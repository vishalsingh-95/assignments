{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33cf2099-4994-46fa-a90f-fc35cc194683",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b0b4fa-1c28-45ed-8dfa-40d6aaf305a9",
   "metadata": {},
   "source": [
    "# Both the t-test and z-test are statistical hypothesis tests used to make inferences about population parameters based on sample data. The main difference between the two lies in the underlying assumptions about the population and the sample size.\n",
    "\n",
    "# The t-test is used when the population standard deviation is unknown or when the sample size is relatively small (typically less than 30). It uses the t-distribution to calculate the test statistic. The t-distribution takes into account the additional uncertainty introduced by estimating the population standard deviation from the sample data. The t-test is appropriate when working with small samples because it provides more conservative results by considering the variability inherent in smaller datasets.\n",
    "\n",
    "# For example:-\n",
    "Let's say we want to test whether there is a significant difference in the mean scores of two groups of students who received different teaching methods. We randomly select 20 students from each group and measure their scores. Since the sample size is relatively small and the population standard deviation is unknown, we would use a t-test to compare the means of the two groups and determine if the difference is statistically significant.\n",
    "\n",
    "\n",
    "\n",
    "# On the other hand, the z-test is used when the population standard deviation is known or when the sample size is large (typically greater than 30). It assumes a normal distribution and uses the standard normal distribution (z-distribution) to calculate the test statistic. The z-test is more powerful and provides more precise results when working with larger sample sizes.\n",
    "\n",
    "# For example:-\n",
    "Suppose we are conducting a study to examine the average height of adults in a particular city. We collect a large random sample of 500 individuals and measure their heights. Since the sample size is large and assuming the population standard deviation is known or can be reasonably estimated, we would use a z-test to test whether the average height of the sample significantly differs from a given population mean.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1405b102-8a09-4109-afb2-ceac4af00445",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ecc525-5be3-4f1a-8a4c-ff563313b9f8",
   "metadata": {},
   "source": [
    "# One-Tailed Test:\n",
    "A one-tailed test, also known as a directional test, is used when the alternative hypothesis specifies a particular direction of the effect or difference between groups. In other words, it focuses on whether the observed data significantly deviates from the null hypothesis in one specific direction. The critical region is only defined on one side of the distribution.\n",
    "\n",
    "# Two-Tailed Test:\n",
    "A two-tailed test, also known as a non-directional test, is used when the alternative hypothesis does not specify a particular direction of the effect or difference. It examines whether the observed data significantly deviates from the null hypothesis in either direction. The critical region is divided on both sides of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e68a52c-3f0b-4652-9ddf-9484f058f6cb",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279fa008-0401-4d3a-8749-a4ebab2b1af9",
   "metadata": {},
   "source": [
    "# Type 1 Error:\n",
    "A Type 1 error, also known as a false positive, occurs when the null hypothesis (H0) is wrongly rejected, even though it is true. In other words, it is the incorrect conclusion that there is a significant effect or difference when, in reality, there is no such effect or difference.\n",
    "\n",
    "# Example scenario of a Type 1 error:\n",
    "Suppose a pharmaceutical company is testing a new drug for a specific disease. The null hypothesis states that the drug has no effect, while the alternative hypothesis suggests that the drug is effective. After conducting a study and analyzing the data, the company incorrectly rejects the null hypothesis and claims that the drug is effective, when, in fact, it has no effect on the disease. This would be a Type 1 error, as the company concluded there was an effect when there was none.\n",
    "\n",
    "# Type 2 Error:\n",
    "A Type 2 error, also known as a false negative, occurs when the null hypothesis (H0) is incorrectly accepted, failing to reject it when it is false. It means failing to detect a significant effect or difference that actually exists.\n",
    "\n",
    "# Example scenario of a Type 2 error:\n",
    "Consider a diagnostic test for a rare disease. The null hypothesis states that the person does not have the disease, while the alternative hypothesis suggests they do have the disease. A Type 2 error would occur if the test incorrectly concludes that an individual does not have the disease (accepts the null hypothesis), when in reality, they do have the disease. In this case, the test fails to detect the disease, leading to a false negative result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ef224-d5f3-4bcb-b132-33db51f22646",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8673d7ef-f05c-43cd-a6ec-9974cb70a86e",
   "metadata": {},
   "source": [
    "# Bayes's theorem is a fundamental concept in probability theory and statistics. It describes how to update or revise the probability of an event based on new information or evidence. The theorem mathematically combines prior knowledge (prior probability) and new data (likelihood) to calculate the updated probability (posterior probability).\n",
    "\n",
    "# The formula for Bayes's theorem is:\n",
    "\n",
    "**P(A|B) = (P(B|A) * P(A)) / P(B)**\n",
    "\n",
    "# Where:\n",
    "- P(A|B) is the posterior probability of event A given event B.\n",
    "- P(B|A) is the likelihood or probability of event B given event A.\n",
    "- P(A) is the prior probability of event A.\n",
    "- P(B) is the prior probability of event B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87305896-1826-49f4-a248-973dcdb5c920",
   "metadata": {},
   "source": [
    "# Suppose we visit a doctor for a routine check-up, and we know that the probability of having a certain disease, let's call it Disease X, in the general population is 0.05% (prior probability). The doctor performs a diagnostic test for Disease X, which is known to have a false-positive rate of 3% (likelihood) and a false-negative rate of 1% (likelihood).\n",
    "\n",
    "# Now, let's say the test result comes back positive (event B). We want to determine the probability that we actually have the disease (event A) given the positive test result.\n",
    "\n",
    "# Using Bayes's theorem, we can calculate the posterior probability:\n",
    "\n",
    "**P(A|B) = (P(B|A) * P(A)) / P(B)**\n",
    "\n",
    "**P(A) = 0.0005 (prior probability of having the disease)**\n",
    "**P(B|A) = 1 - 0.01 = 0.99 (likelihood of a positive test result given you have the disease)**\n",
    "**P(B) = P(B|A) * P(A) + P(B|not A) * P(not A)**\n",
    "**= 0.99 * 0.0005 + 0.03 * (1 - 0.0005) (considering false positives and true negatives)**\n",
    "**≈ 0.0005445**\n",
    "\n",
    "# Now, plugging these values into the formula:\n",
    "\n",
    "**P(A|B) = (0.99 * 0.0005) / 0.0005445**\n",
    "**≈ 0.911**\n",
    "\n",
    "# So, given a positive test result, the posterior probability of actually having the disease is approximately 0.911, or 91.1%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2fb87a-45d6-438f-b467-23d1292244ac",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4477529-a5e0-4d03-92b9-5c000d80faca",
   "metadata": {},
   "source": [
    "# A confidence interval is a range of values that provides an estimate of the plausible range for an unknown population parameter, such as a mean or proportion. It quantifies the uncertainty associated with estimating the parameter based on a sample.\n",
    "\n",
    "# To calculate a confidence interval, we typically need three pieces of information: the sample statistic (e.g., mean or proportion), the standard error (a measure of the variability of the sample statistic), and the desired level of confidence.\n",
    "\n",
    "# For example:-\n",
    "\n",
    "Suppose we want to estimate the average height of a population of adults. We collect a random sample of 100 individuals from this population and measure their heights. The sample mean height is 170 cm, and the sample standard deviation is 5 cm.\n",
    "\n",
    "To calculate a 95% confidence interval for the population mean height, follow these steps:\n",
    "\n",
    "1) Determine the desired level of confidence. In this case, it's 95%, which corresponds to a significance level of α = 0.05.\n",
    "\n",
    "2) Calculate the standard error of the mean (SE), which is the standard deviation of the sample divided by the square root of the sample size. In this example, SE = 5 / √100 = 0.5.\n",
    "\n",
    "3) Determine the critical value from the appropriate distribution. Since the sample size is large (n > 30), we can use the standard normal distribution. For a 95% confidence level, the critical value (z*) is approximately 1.96.\n",
    "\n",
    "4) Calculate the margin of error, which is the product of the critical value and the standard error: Margin of Error = z* * SE = 1.96 * 0.5 = 0.98.\n",
    "\n",
    "5) Construct the confidence interval by subtracting and adding the margin of error to the sample mean: Confidence Interval = Sample Mean ± Margin of Error = 170 ± 0.98.\n",
    "\n",
    "# In this example, the 95% confidence interval for the population mean height would be [169.02, 170.98] cm. This means that we are 95% confident that the true population mean height lies within this interval.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638501a2-7939-4417-9e66-63c588e79551",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b40726f-6162-47b7-90bc-e9baef1dd7f0",
   "metadata": {},
   "source": [
    "# Let's say we have a box of 100 colored marbles. The marbles are either red or blue. We know that 60% of the marbles are red (prior probability), and the remaining 40% are blue. Additionally, we also know that when we randomly select a red marble from the box, the chance of it being smooth is 70% (likelihood), while the chance of a blue marble being smooth is only 30% (likelihood).\n",
    "\n",
    "# Now, we randomly pick a smooth marble from the box (event B), and we want to determine the probability that it is red (event A).\n",
    "\n",
    "# Using Bayes's theorem, we can calculate the posterior probability:\n",
    "\n",
    "**P(A|B) = (P(B|A) * P(A)) / P(B)**\n",
    "\n",
    "**P(A) = 0.6 (prior probability of selecting a red marble)**\n",
    "**P(B|A) = 0.7 (likelihood of selecting a smooth marble given it's red)**\n",
    "**P(B) = P(B|A) * P(A) + P(B|not A) * P(not A)**\n",
    "**= 0.7 * 0.6 + 0.3 * (1 - 0.6)**\n",
    "**= 0.42 + 0.18**\n",
    "**= 0.6**\n",
    "\n",
    "# Now, plugging these values into the formula:\n",
    "\n",
    "**P(A|B) = (0.7 * 0.6) / 0.6**\n",
    "**= 0.7**\n",
    "\n",
    "# Therefore, given that we randomly selected a smooth marble from the box, the posterior probability of it being red is 0.7, or 70%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c620b865-f5e3-45f2-bda0-b39937007340",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ba2c2a-5e0f-48b1-a2b6-b13bd5767233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59d2168-f36e-44f0-804d-67f25d3edb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: (49.02001800772997, 50.97998199227003)\n"
     ]
    }
   ],
   "source": [
    "sample_mean=50\n",
    "sample_std=5\n",
    "sample_size=100\n",
    "\n",
    "confidence_level=0.95\n",
    "alpha=1-confidence_level\n",
    "\n",
    "critical_value=stats.norm.ppf(1-alpha/2)\n",
    "margin_of_error=critical_value*(sample_std/(sample_size**0.5))\n",
    "\n",
    "\n",
    "confidence_interval = (sample_mean - margin_of_error, sample_mean + margin_of_error)\n",
    "\n",
    "print(\"95% Confidence Interval:\", confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f127a755-ae62-45aa-b56c-2b255f11c6fe",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf5419a-cd72-4529-89e6-3e0333f5ea55",
   "metadata": {},
   "source": [
    "# The margin of error in a confidence interval is a measure of the uncertainty or variability associated with estimating a population parameter based on a sample. It quantifies the amount of deviation or error that is likely to occur between the sample statistic and the true population parameter.\n",
    "\n",
    "# A larger margin of error indicates a wider range of plausible values for the population parameter, reflecting greater uncertainty in the estimation. Conversely, a smaller margin of error indicates a narrower range of plausible values, indicating higher precision in the estimation.\n",
    "\n",
    "**margin_of_error=(critical_value)(sample_standard_deviation/sqrt(sample_size))**\n",
    "# As we can see from the above formula that the margin of error is inversely proportional to the root of sample size.\n",
    "\n",
    "# Sample size directly affects the margin of error. As the sample size increases, the margin of error decreases. This is because a larger sample size provides more information and reduces the sampling variability, leading to a more precise estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc63878c-fa21-44c9-a34d-0136891b4d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The margin of error for sample size 100 is: 0.979981992270027\n",
      "The margin of error for sample size 500 is: 0.43826127028829076\n",
      "95% Confidence Interval for sample size 100: (49.02001800772997, 50.97998199227003)\n",
      "95% Confidence Interval for sample size 500: (49.561738729711706, 50.438261270288294)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "sample_mean=50\n",
    "sample_std=5\n",
    "sample_size1=100\n",
    "sample_size2=500\n",
    "\n",
    "confidence_level=0.95\n",
    "alpha=1-confidence_level\n",
    "\n",
    "critical_value=stats.norm.ppf(1-alpha/2)\n",
    "margin_of_error1=critical_value*(sample_std/(sample_size1**0.5))\n",
    "margin_of_error2=critical_value*(sample_std/(sample_size2**0.5))\n",
    "\n",
    "confidence_interval1 = (sample_mean - margin_of_error1, sample_mean + margin_of_error1)\n",
    "confidence_interval2 = (sample_mean - margin_of_error2, sample_mean + margin_of_error2)\n",
    "print(\"The margin of error for sample size 100 is:\",margin_of_error1)\n",
    "print(\"The margin of error for sample size 500 is:\",margin_of_error2)\n",
    "print(\"95% Confidence Interval for sample size 100:\", confidence_interval1)\n",
    "print(\"95% Confidence Interval for sample size 500:\", confidence_interval2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330af22d-5951-43b3-9c96-078aa5a99272",
   "metadata": {},
   "source": [
    "# Here we have repeated example in Q7 with 2 sample sizes and we can see that the margin of error is less when sample size is more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49699bd-2d9f-4018-8c8f-53d3eee802d6",
   "metadata": {},
   "source": [
    "# Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a99fb944-21cd-4075-a579-44cd3a23a3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_mean=70\n",
    "sample_std=5\n",
    "data_point=75\n",
    "z_score=(data_point-sample_mean)/sample_std\n",
    "z_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03e9b09-1aa7-457f-aad1-ab57092ceadd",
   "metadata": {},
   "source": [
    "# Z_score of 1 means that the data point lies exactly 1 standard deviation away from the mean value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aed48aa-09ae-4f07-a76c-1e83ce6096e4",
   "metadata": {},
   "source": [
    "# Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fd6bb27-a915-4600-bf18-ad4c25cd4c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: 16.970562748477143\n",
      "Critical t-value: 2.009575234489209\n",
      "p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "sample_mean=6\n",
    "sample_std=2.5\n",
    "sample_size=50\n",
    "population_mean=0 # assumed the null hypothesis that the drug has no effect\n",
    "\n",
    "confidence_level=0.95\n",
    "alpha=1-confidence_level\n",
    "\n",
    "t_stat=(sample_mean-population_mean)/(sample_std/(sample_size**0.5))\n",
    "\n",
    "degree_of_freedom=sample_size-1\n",
    "\n",
    "critical_t_value=stats.t.ppf(1-alpha/2,degree_of_freedom)\n",
    "p_value = 2 * (1 - stats.t.cdf(t_stat, degree_of_freedom))\n",
    "\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"Critical t-value:\", critical_t_value)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e283cbf-bda9-4843-a2ff-88b12eded993",
   "metadata": {},
   "source": [
    "# Here we can see the P value is less than the significance level therefore we reject the null hypothesis that, the drug has no effect on the people."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3139ffc-8ce7-4844-9958-437684f2e8e1",
   "metadata": {},
   "source": [
    "# Q11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "878e54f2-72fa-4186-a582-66eb9a1b765c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: (0.6300591122018828, 0.6699408877981172)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "sample_proportion=0.65\n",
    "sample_size=500\n",
    "\n",
    "standard_error=(sample_proportion*(1-sample_proportion))/(sample_size**0.5)\n",
    "\n",
    "confidence_level=0.95\n",
    "alpha=1-confidence_level\n",
    "\n",
    "critical_value = stats.norm.ppf(1 - alpha / 2)\n",
    "\n",
    "margin_of_error=critical_value*standard_error\n",
    "\n",
    "confidence_interval = (sample_proportion - margin_of_error, sample_proportion + margin_of_error)\n",
    "\n",
    "print(\"95% Confidence Interval:\", confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5407d92f-6c98-49d1-aac2-20e9b054c6af",
   "metadata": {},
   "source": [
    "# We can conclude that 63% to 67% people are happy with their current jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f278d38a-ed29-426f-9b02-192999a1d5b4",
   "metadata": {},
   "source": [
    "# Q12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "079d65f2-70d5-4340-8de4-dd5902006c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The t_stat is 8.588975014708023 and the p_value is 3.3344977165574746e-17\n",
      "There is a significant difference between the teaching methods.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Sample A\n",
    "sample_A_mean=85\n",
    "sample_A_std=6\n",
    "sample_A_size=500\n",
    "\n",
    "# Sample B\n",
    "\n",
    "sample_B_mean=82\n",
    "sample_B_std=5\n",
    "sample_B_size=500\n",
    "\n",
    "alpha=0.01\n",
    "\n",
    "t_stat,p_value=stats.ttest_ind_from_stats(sample_A_mean, sample_A_std, sample_A_size,sample_B_mean, sample_B_std, sample_B_size)\n",
    "print(\"The t_stat is {} and the p_value is {}\".format(t_stat,p_value))\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference between the teaching methods.\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the teaching methods.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b219b9-b343-4d78-afb7-2775a2830cc6",
   "metadata": {},
   "source": [
    "# Q13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ee6bc14-2de9-4140-8c18-75fb978f125d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confidence interval for confidence level of 0.9 is [63.10,66.90]\n"
     ]
    }
   ],
   "source": [
    "population_mean=60\n",
    "population_std=8\n",
    "sample_mean=65\n",
    "sample_size=50\n",
    "\n",
    "confidence_level=0.90\n",
    "\n",
    "dof=sample_size-1\n",
    "\n",
    "t_stat=stats.t.ppf((1+confidence_level)/2,dof)\n",
    "standard_error=population_std/(sample_size**0.5)\n",
    "\n",
    "margin_of_error=t_stat*standard_error\n",
    "\n",
    "lower_bound=sample_mean-margin_of_error\n",
    "upper_bound=sample_mean+margin_of_error\n",
    "\n",
    "print(\"The confidence interval for confidence level of 0.9 is [{:.2f},{:.2f}]\".format(lower_bound,upper_bound))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18dea3e-3741-4812-bd37-ba0fcd30c39c",
   "metadata": {},
   "source": [
    "# Here we can see that the 90% confidence interval of population means estimated by the given sample size is not containing the actual population mean given in the question, so we can say that the sample data is not sufficient enough to get to the original population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d421e9d-3897-47a0-a7f8-b4fddc0b8bbe",
   "metadata": {},
   "source": [
    "# Q14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b91379f2-5c45-4780-a3c0-0a3eb8a2aa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a significant effect of caffiene on reaction time.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "mean_reaction_time=0.25\n",
    "std_reaction_time=0.05\n",
    "sample_size=30\n",
    "population_mean=0# assuming no significant effect of caffiene on reaction time\n",
    "confidence_level=0.9\n",
    "\n",
    "sample_data = np.random.normal(loc=sample_mean, scale=sample_std, size=sample_size)\n",
    "\n",
    "t_stat,p_value=stats.ttest_1samp(a=sample_data, popmean=population_mean,alternative='two-sided')\n",
    "\n",
    "alpha=1-confidence_level\n",
    "\n",
    "if p_value<alpha:\n",
    "    print(\"There is a significant effect of caffiene on reaction time.\")\n",
    "else:\n",
    "    print(\"There is no significant effect of caffiene on reaction time.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dba4883-8879-4797-9a8f-914713344ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
